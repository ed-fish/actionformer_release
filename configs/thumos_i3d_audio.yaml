dataset_name: thumos_audio
train_split: ['validation']
val_split: ['test']
dataset: {
  json_file: ./data/thumos/annotations/thumos14.json,
  feat_folder: /mnt/welles/scratch/datasets/thumos/i3d/,
  audio_folder: /mnt/welles/scratch/datasets/thumos/audio_features,
  file_prefix: ~,
  file_ext: .npy,
  num_classes: 20,
  input_dim: 2048, #!if [ "$(audio_dataset_fuse)" = "concat" ] then 2176 else 2048,
  feat_stride: 4,
  num_frames: 16,
  # serve as data augmentation
  trunc_thresh: 0.5,
  crop_ratio: [0.9, 1.0],
  max_seq_len: 2304,
  use_audio: True,
  audio_format: vgg # raw, vgg, mel_spec
}

model: {
  fpn_type: identity,
  fpn_dim: 512,
  max_buffer_len_factor: 6.0,
  n_mha_win_size: 19,
  backbone_type: convPooler,
  backbone_arch: [2, 5],
  audio_fusion_loc: ["pre-neck", "pre-reg"],  # pre-neck, pre-backbone, pre-cls, pre-reg
  audio_fusion_method: concat, # concat, sum, cross_att
  fpn_norm: groupnorm,
  use_abs_pe: True,
  audio_embd_dim: 128,
  embd_dim: 512, 
}
opt: {
  learning_rate: 0.0001,
  epochs: 45,
  weight_decay: 0.05,
}
loader: {
  batch_size: 2,
}
train_cfg: {
  init_loss_norm: 100,
  clip_grad_l2norm: 1.0,
  cls_prior_prob: 0.01,
  center_sample: radius,
  center_sample_radius: 1.5,
  use_audio: True,
  label_smoothing: 0.0,
  droppath: 0.1,
}
test_cfg: {
  voting_thresh: 0.7,
  pre_nms_topk: 2000,
  max_seg_num: 200,
  min_score: 0.001,
  # when using external scores, our model is generating "proposals"
  # multiclass_nms: False,
  # ext_score_file: ./data/thumos/annotations/thumos14_cls_scores.pkl,
  # comment out L47-48 and uncomment L50 to disable score fusion
  multiclass_nms: True,
}
output_folder: ./ckpt/